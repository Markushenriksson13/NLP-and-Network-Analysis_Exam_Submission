{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetFit model training using the created JSON file \n",
    "### 'breaking_bad_analysisV2.json' from (M2_LLM_Data_Fetch_and_Processing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages from requirements.txt\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# import libs\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load JSON and prepare data for classification\"\"\"\n",
    "    with open(\"breaking_bad_analysisV2.json\", 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    relationships = []\n",
    "    labels = []\n",
    "\n",
    "    for episode in data.values():\n",
    "        for rel in episode.get('relationships', []):\n",
    "            relationships.append(f\"{rel['source']} - {rel['target']}\")\n",
    "            labels.append(rel['relation'])\n",
    "\n",
    "    # Split into train/test (80/20)\n",
    "    df = pd.DataFrame({'text': relationships, 'label': labels})\n",
    "    train_size = int(len(df) * 0.8)\n",
    "\n",
    "    train_data = Dataset.from_pandas(df[:train_size])\n",
    "    test_data = Dataset.from_pandas(df[train_size:])\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def train_and_evaluate():\n",
    "    # Load and prepare data\n",
    "    train_dataset, test_dataset = load_and_prepare_data()\n",
    "\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Testing samples: {len(test_dataset)}\")\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "    trainer = SetFitTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        batch_size=16,\n",
    "        num_iterations=20,\n",
    "        num_epochs=1\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate\n",
    "    predictions = model.predict(test_dataset['text'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_dataset['label'], predictions))\n",
    "\n",
    "    # Example predictions\n",
    "    print(\"\\nExample Predictions:\")\n",
    "    for text, true_label, pred_label in zip(\n",
    "        test_dataset['text'][:3],\n",
    "        test_dataset['label'][:3],\n",
    "        predictions[:3]\n",
    "    ):\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"True: {true_label}\")\n",
    "        print(f\"Predicted: {pred_label}\")\n",
    "\n",
    "    # Save Model\n",
    "    model.save_pretrained(\"saved_model\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# run train & evaluation\n",
    "model = train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
